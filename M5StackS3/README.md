# M5Stack S3 Camera + SD + Dummy Inference System  
（現状仕様まとめ & 今後の作業計画）

---

## 📌 現在の仕様（2025/xx 時点）

### 1. **カメラ入力**
- 使用カメラ：ESP32-S3 内蔵カメラインターフェイス（OV系・RGB565/QVGA 320×240）
- 取得フレームサイズ：**QVGA (320×240)**
- Pixel format：**RGB565**
- フレームは `esp_camera_fb_get()` で取得

---

### 2. **画像前処理と推論フロー**

#### 📸 画像処理の流れ
1. **カメラから320×240画像を取得**
   - フォーマット：RGB565

2. **中央 240×240 をトリミング**
   - 320×240 から横40px（左右20pxずつ）をカットし、正方形化
   - トリミング後画像を `g_crop240` バッファへ格納（RGB565形式）

3. **64×64 へ縮小（CNN入力用）**
   - 240×240画像を最近傍補間で64×64にリサイズ
   - RGB565 → グレースケール変換
   - NN入力用画像バッファ `g_nn_input` に格納
   - **このミニマムサイズ（64×64）のデータをCNNへ投入**

#### 🧠 CNN推論と座標変換
4. **CNN推論実行**
   - 入力：64×64グレースケール画像
   - 出力：バウンディングボックス座標（64×64画像座標系）

5. **BB座標を240×240へスケール変換**
   ```cpp
   // 64×64 → 240×240 へのスケール係数
   float scale = 240.0f / 64.0f;  // = 3.75
   
   // BB座標の変換
   int x1_240 = (int)(x1_64 * scale);
   int y1_240 = (int)(y1_64 * scale);
   int x2_240 = (int)(x2_64 * scale);
   int y2_240 = (int)(y2_64 * scale);
   ```

6. **240×240画像にBBを描画**
   - 変換後の座標を使用して `g_crop240` バッファにバウンディングボックスを描画
   - 色：赤枠（RGB565: 0xF800）

7. **ディスプレイに表示**
   - BB描画済みの240×240画像を320×240ディスプレイの中央に配置


#### 💡 座標系の関係
```
カメラ出力    トリミング    CNN入力      CNN出力        描画対象
320×240   →  240×240   →  64×64    →  BB(64×64)  →  BB(240×240)
(RGB565)     (RGB565)     (Gray)       座標変換       (RGB565)
                ↑                                        ↑
                |________ この画像バッファを保持 ________|
```

---

### 3. **SDカード処理**
- SDは **SPI直叩き** で初期化  
  → I2C競合なし（M5UnifiedのSDを使わないため）
- 使用ピン（M5Stack S3実機と一致）  
  - SCK ＝ 36  
  - MISO ＝ 35  
  - MOSI ＝ 37  
  - CS ＝ 4  

### 4. **モデルファイル読み込み**
- モデルファイル名：`/UHD64x64.model`
- microSDの存在チェックのみ実施
- 中身はまだ読み込まない（ESP-DL統合前段階）

---

### 5. **推論ロジック（現状はダミー）**
- モデルファイルが存在しない場合  
  → `(50,50)-(100,100)` のダミーBB描画
- モデルが存在する場合  
  → 現段階は中央付近の仮BB  
  → ここに ESP-DL 推論結果を後で組み込む予定

---

### 6. **ディスプレイ表示**
- 320×240 の中央に 240×240 を配置
- 赤枠のBBを描画後に出力
- M5Unified の Display APIを活用
- I2C競合回避のため、カメラ使用直前に  
  `M5.In_I2C.release()` を毎フレーム実施

---

## 🔧 現状の安定性
- **I2C競合なし（SDをSPI直叩きにしたため完全解決）**
- **PlatformIOでの書き込みも成功**
- **Camera → Crop → Resize → BB描画 → LCD出力 の一連処理は正常動作**

---

# 🚀 今後の作業計画（ステップ順）

## ✅ Step 1：ESP-DL の推論処理を組み込み
- `g_nn_input (64×64)` を NN に渡す  
- 出力 → bounding box またはクラス確率
- 現在のダミーコードを **実推論へ差し替え**

---

## ✅ Step 2：モデルファイル(.model)のフォーマット決定
- ESP-DL推奨は binary blob
- 読み込み → RAM or PSRAM へ展開
- モデルサイズ 5–6MB 程度なら PSRAM 利用前提

---

## ✅ Step 3：推論結果を 240×240 座標へスケール
例：  
64×64 → 240×240  
```
scale = 240 / 64 = 3.75
x1_240 = x1_64 * scale
…
```

---

## ✅ Step 4：FPS向上（最適化）
- `nearest-neighbor` → `bilinear` へ変更するか検討
- PSRAM DMA の有効利用
- `writePixels()` の高速化

---

## ✅ Step 5：UI追加（必要なら）
- 推論時のラベル表示
- FPS表示
- モデル読み込みステータス表示

---

# ✔ 最終ゴール（完成形）

1. **M5Stack S3 単体でリアルタイム推論**
2. microSDに置いたモデルを読み込み
3. カメラ映像に BB を描画
4. 30FPS前後で動作
5. PlatformIOビルドで開発しやすい構成

---

# 📄 このファイルについて
この markdown はあなたの現在の開発状況を整理し、  
次の作業項目を明確にするためのドキュメントです。

いつでも追記版を生成できます。
